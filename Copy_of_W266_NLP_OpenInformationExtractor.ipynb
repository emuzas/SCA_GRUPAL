{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emuzas/SCA_GRUPAL/blob/main/Copy_of_W266_NLP_OpenInformationExtractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W266 NLP Open Information Extractor for Cyber Threat Intelligence\n"
      ],
      "metadata": {
        "id": "1JiOUUC4EtyW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCoxTOMFhAAV"
      },
      "source": [
        "# Block 1: Installtions and drives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFWCB5RT_hFl"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBWtEhfeBwL-"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV6myqGCB45R"
      },
      "outputs": [],
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbTZ7SjHB3yd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNM0n6cu_mo0"
      },
      "outputs": [],
      "source": [
        "your_module = drive.CreateFile({'id':'1YlZBlvViO4Iz0xU-6aPS5lUzL6O0nxHg'})\n",
        "\n",
        "your_module.GetContentFile('spacy_wrapper.py')\n",
        "\n",
        "your_module2= drive.CreateFile({'id':'1l8Sd_CrGY8Mk6hy9uhwGZnkrKRwSACX5'})\n",
        "\n",
        "your_module2.GetContentFile('symbols.py')\n",
        "\n",
        "your_module3= drive.CreateFile({'id':'1X6gc4BOll6iweDl7gFs4PmPi5w514Qhg'})\n",
        "\n",
        "your_module3.GetContentFile('load_pretrained_word_embeddings.py')\n",
        "\n",
        "your_module4= drive.CreateFile({'id':'1XhgGTsqee49it6xdLdAa69cWNVNGNdX5'})\n",
        "\n",
        "your_module4.GetContentFile('word_index.py')\n",
        "\n",
        "your_module5= drive.CreateFile({'id':'1NO71gAICxxpe3JfRcvTFicQIhUiHpIPZ'})\n",
        "\n",
        "your_module5.GetContentFile('elmo.py')\n",
        "\n",
        "your_module6= drive.CreateFile({'id':'1xUn888UMox08U2dxgBR1WmULPKQ0jyzB'})\n",
        "\n",
        "your_module6.GetContentFile('utils.py')\n",
        "\n",
        "your_module7= drive.CreateFile({'id':'1Y3pdrMF-5cha__aG3MKHkj0ydhBO0BDX'})\n",
        "\n",
        "your_module7.GetContentFile('Alayers.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNSGfSj_8hSx",
        "outputId": "4f4fb242-40d5-4acc-f09c-08fd42e76a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "2.8.0\n",
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import datetime\n",
        "print(tf.version.VERSION)\n",
        "print(keras.__version__)\n",
        "print(tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Fr1m72Nfq29k",
        "outputId": "ad5f9e87-eef8-47a9-e97f-a107e0e83a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiny-tokenizer\n",
            "  Downloading tiny_tokenizer-3.4.0.tar.gz (971 bytes)\n",
            "Building wheels for collected packages: tiny-tokenizer\n",
            "  Building wheel for tiny-tokenizer (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for tiny-tokenizer\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for tiny-tokenizer\n",
            "Failed to build tiny-tokenizer\n",
            "Installing collected packages: tiny-tokenizer\n",
            "    Running setup.py install for tiny-tokenizer ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-yv4mc9d6/tiny-tokenizer_2b7bfdaaf7804282a2c77e1061139b94/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-yv4mc9d6/tiny-tokenizer_2b7bfdaaf7804282a2c77e1061139b94/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-m9l1k8e1/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/tiny-tokenizer Check the logs for full command output.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
            "\u001b[K     |████████████████████████████████| 401 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 64.2 MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 26.3 MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 66.0 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 81.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from flair) (8.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.11.0+cu113)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.0)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (3.7.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (6.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.3.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 84.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Collecting requests\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.12)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 77.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 87.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Building wheels for collected packages: mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=752a0d10307728f35e006777f64d264b952843dc09534d43059ba4b101c2c172\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=d138dfa690c643baf3d041fe526655480e98ce83f85ea7a50d6d6268c7bd807f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=161a26383a9c060edbc2225728b8e06d5b07645950f3f44f69b388e849db548d\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=e1fb6a101b0667c6f8f87d9d45c4e2532f4e18ad8bfa8a89b20b416426570dcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=3671f981fc5e46883cb247a012576b8dea808c976a088250b0606c4e7a745005\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=705b52a2b27243b322080a57c83f2bee7e1d64b330c332b0eec2dd9938606df3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, langdetect, konoha, janome, hyperopt, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.4\n",
            "    Uninstalling importlib-metadata-4.11.4:\n",
            "      Successfully uninstalled importlib-metadata-4.11.4\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 huggingface-hub-0.7.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.5 pyyaml-6.0 requests-2.27.1 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.12.1 transformers-4.19.2 wikipedia-api-0.5.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import keras\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, Activation, Dropout\n",
        "from typing import List\n",
        "import torch\n",
        "import os\n",
        "import re\n",
        "torch.cuda.current_device(),torch.cuda.device_count(),torch.cuda.is_available()\n",
        "!pip install tiny-tokenizer\n",
        "!pip install flair\n",
        "#!pip install konoha\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "#import flair\n",
        "from flair.data import  Sentence, Token\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, \\\n",
        "    CharLMEmbeddings\n",
        "from typing import List\n",
        "import torch\n",
        "import os\n",
        "import re\n",
        "from flair.embeddings import BertEmbeddings\n",
        "from flair.embeddings import TransformerWordEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juP3_bavhVt5"
      },
      "source": [
        "# Block 2: Creating XLNet Embeddings Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4rbqyi4bOmK"
      },
      "source": [
        "Block 2: Creating XLNet embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "a4eb63fa479f4d96839e727c0ddf4ef8",
            "6ebdbe950b6041da9a881c6a3d4e1ce7",
            "552add47ffc544b295c11bf206a24963",
            "0d20b4c6f0c8437286eda40cd4bf59db",
            "6db55541bde442b0af866cbac6b5eb8a",
            "07fbb3fb0cd14e038ba30b36c4ea1aed",
            "d7762137ab8248edb18505a6a35351f7",
            "c7b2906b95e04a41a5c29819985d178d",
            "49a5901e71554a9e91b76ac175644fb4",
            "f7955b12acec412699544b19bf5d8263",
            "d005300539a74680a12efc4df9ec9f8a",
            "515831f556884e828a6e992b2d45ca7a",
            "76c1106aa0cb4bf9bbc724a9f6244e7e",
            "fbc87a275067477bbf21aa0b4b13f3b1",
            "9e4ac76061b04a04b55509a06d65e756",
            "83145666a7904f3fbc84a1d80acd83b3",
            "87998ac5d26045f1918b9044de0163ae",
            "eb484ad1f9fb462eba401158cd819bfe",
            "06c6c9609906489fa8f0f038c6dae18d",
            "b29932257842417bbba283a66651de85",
            "3dcdea470e7042b79e84efb4d81febfa",
            "33e210e461b94cd6be87ce1ec0739f3f",
            "84b2b958465946708d491b55de3bde20",
            "7c6bd31809c84286adfe94cb024d29e5",
            "f39d609c8961479683b54cc2c40a1408",
            "8c68b9f836a24e5b9721e7acb342dbcc",
            "b40089e3908a41c4af3965f5789874f2",
            "37413b4ee52b4e92a13b4518e9f11b80",
            "4da5b5b6cacb4f54b4216d786b1b0a90",
            "d0132d6d671149928383f80e5208a39b",
            "14b0aa8eb4984b94b6a73e5791c23bb9",
            "07f1617f020e4c94b530f8da3522d522",
            "12dae2270b114e2c8b7a6d9dc48bb5b7",
            "8e5d1f065ed04fb5aa9888b5cfb0ee5a",
            "83b107b3eeb14863b5551cf9250e78b3",
            "63f6eaede3bb4ed5b0bdd2bafd835362",
            "fd34db7a59454e6a9b50e8728e285789",
            "d1b2883d5bf541848baaa07d51998995",
            "c97aa01f5fce48d89539d5cd0a2a8b3f",
            "71a679d2562f4182ae99870e4226b339",
            "e1c8a247162c429abbf086902753857b",
            "21abc1c9bcbc4f39b9b33d49e96169e7",
            "7358b218b0ea473895465f321dd001c2",
            "c4114a05f4bf414ba7093018cb0452d4"
          ]
        },
        "id": "CL3tZkILVZen",
        "outputId": "69fd305d-7112-428a-c15b-986c6e83bd25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4eb63fa479f4d96839e727c0ddf4ef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "515831f556884e828a6e992b2d45ca7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84b2b958465946708d491b55de3bde20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e5d1f065ed04fb5aa9888b5cfb0ee5a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Init embedding\n",
        "\n",
        "xln = TransformerWordEmbeddings('xlm-roberta-large')\n",
        "emb_size= 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejv7vHoSY26t"
      },
      "outputs": [],
      "source": [
        "def create_XLNET_embeddings(elmo, documents, max_sentences = 10):\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    #xln = XLMRobertaEmbeddings()\n",
        "    xln = TransformerWordEmbeddings('xlm-roberta-large')\n",
        "    emb_size= 1024\n",
        "    while True:\n",
        "      for row in documents:\n",
        "          my_sent = row\n",
        "          sentence = Sentence(str(my_sent))\n",
        "          xln.embed(sentence)\n",
        "\n",
        "          x = []\n",
        "          for token in sentence:\n",
        "            x.append(token.embedding.cpu().detach().numpy())\n",
        "            if len(x) == max_sentences:\n",
        "              break\n",
        "\n",
        "          while len(x) < max_sentences:\n",
        "            x.append(np.zeros(emb_size))\n",
        "          embeddings.append(x)\n",
        "      return np.array(embeddings)\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYv_ZntIiWKC"
      },
      "source": [
        "# Block 3: All functions + Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl0vhCO_wBCB"
      },
      "outputs": [],
      "source": [
        "#-----------The functions here are originally from with some modifications --> Stanvosky et al. Please refer/cite his work: Stanovsky, Gabriel, et al. \"Supervised open information extraction.\" Proceedings of the 2018 Conference\n",
        "#of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). 2018. ---------------\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from keras.utils import np_utils\n",
        "import pandas as pd\n",
        "\n",
        "sent_maxlen = 20\n",
        "classes = None\n",
        "encoder =  LabelEncoder()\n",
        "batch_size = 5\n",
        "epochs=10\n",
        "emb_dropout = 0.1\n",
        "trainable_emb = True\n",
        "pos_tag_embedding_size = 5\n",
        "num_of_latent_layers = 2\n",
        "\n",
        "#hidden_units = pow(2, 7)\n",
        "hidden_units = pow(2, 9)\n",
        "pred_dropout=0.1\n",
        "\n",
        "class Sample:\n",
        "    \"\"\"\n",
        "    Single sample representation.\n",
        "    Containter which names spans in the input vector to simplify access\n",
        "    \"\"\"\n",
        "    def __init__ (self, word):\n",
        "        self.word = word\n",
        "\n",
        "    def encode(self):\n",
        "        \"\"\"\n",
        "        Encode this sample as vector as input for rnn,\n",
        "        Probably just concatenating members in the right order.\n",
        "        \"\"\"\n",
        "        return self.word\n",
        "\n",
        "class Pad_sample(Sample):\n",
        "    \"\"\"\n",
        "    A dummy sample used for padding\n",
        "    \"\"\"\n",
        "    #Sample( word = 0 )\n",
        "    def __init__(self):\n",
        "        Sample.__init__(self, word = 0)\n",
        "\n",
        "def pad_sequences(sequences, pad_func, maxlen = None):\n",
        "    \"\"\"\n",
        "    Similar to keras.preprocessing.sequence.pad_sequence but using Sample as higher level\n",
        "    abstraction.\n",
        "    pad_func is a pad class generator.\n",
        "    \"\"\"\n",
        "    ret = []\n",
        "\n",
        "    max_value = max(map(len, sequences))\n",
        "    if maxlen is None:\n",
        "        maxlen = max_value\n",
        "\n",
        "    # Pad / truncate (done this way to deal with np.array)\n",
        "    for sequence in sequences:\n",
        "        cur_seq = list(sequence[:maxlen])\n",
        "        cur_seq.extend([pad_func()] * (maxlen - len(sequence)))\n",
        "        ret.append(cur_seq)\n",
        "    return ret\n",
        "\n",
        "\n",
        "def classes_():\n",
        "        \"\"\"\n",
        "        Return the classes which are classified by this model\n",
        "        \"\"\"\n",
        "        return encoder.classes_\n",
        "\n",
        "def num_of_classes():\n",
        "        \"\"\"\n",
        "        Return the number of ouput classes\n",
        "        \"\"\"\n",
        "        return len(classes_())\n",
        "\n",
        "def load_dataset(fn,T):\n",
        "\n",
        "      df = pandas.read_csv(fn,sep= \"\\t\",header=0,keep_default_na=False)\n",
        "\n",
        "      if T==\"train\":\n",
        "        encoder.fit(df.label.values)\n",
        "      else:\n",
        "            df = pandas.read_csv(fn,\n",
        "                         sep= \"\\t\",\n",
        "                         header=0,\n",
        "                         keep_default_na=False)\n",
        "      sents = get_sents_from_df(df)\n",
        "\n",
        "      return (encode_outputs(sents))\n",
        "\n",
        "def load_datasetTestRE(fn,T):\n",
        "\n",
        "      if T==\"test_RE\":\n",
        "          df = pandas.read_csv(fn,\n",
        "                         sep= \";\",\n",
        "                         header=0,\n",
        "                         keep_default_na=False)\n",
        "          df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "          df.word_id = pd.to_numeric(df.word_id, errors='coerce').astype('Int64')\n",
        "          df.run_id = pd.to_numeric(df.run_id, errors='coerce').astype('Int64')\n",
        "          df.sent_id = pd.to_numeric(df.sent_id, errors='coerce').astype('Int64')\n",
        "          df.head_pred_id = pd.to_numeric(df.head_pred_id, errors='coerce').astype('Int64')\n",
        "          df = df[df.word.apply(lambda x : len(x)>0)]\n",
        "      else:\n",
        "            df = pandas.read_csv(fn,\n",
        "                         sep= \"\\t\",\n",
        "                         header=0,\n",
        "                         keep_default_na=False)\n",
        "\n",
        "      if T==\"train\":\n",
        "        encoder.fit(df.label.values)\n",
        "\n",
        "      sents = get_sents_from_df(df)\n",
        "      return (encode_outputs(sents))\n",
        "\n",
        "def load_dataset_encodeinputs(fn,T):\n",
        "      if \"RE\" in T:\n",
        "          df = pandas.read_csv(fn,\n",
        "                         sep= \";\",\n",
        "                         header=0,\n",
        "                         keep_default_na=False)\n",
        "          df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "          df.word_id = pd.to_numeric(df.word_id, errors='coerce').astype('Int64')\n",
        "          df.run_id = pd.to_numeric(df.run_id, errors='coerce').astype('Int64')\n",
        "          df.sent_id = pd.to_numeric(df.sent_id, errors='coerce').astype('Int64')\n",
        "          df.head_pred_id = pd.to_numeric(df.head_pred_id, errors='coerce').astype('Int64')\n",
        "          df = df[df.word.apply(lambda x : len(x)>0)] #to skip null values\n",
        "\n",
        "      else:\n",
        "        df = pandas.read_csv(fn,sep= \"\\t\",header=0,keep_default_na=False)\n",
        "\n",
        "      if T==\"train\" or T==\"POS_train\" or T==\"train_xlnet_words\" or T==\"train_xlnet_pred\":\n",
        "        encoder.fit(df.label.values)\n",
        "\n",
        "\n",
        "      sents = get_sents_from_df(df)\n",
        "      if T==\"POS_train\" or T==\"POS\" or T== \"dev_xlnet_pos\" or T==\"test_xlnet_pos_RE\" or T==\"test_xlnet_pos_\":\n",
        "        return getPOS(sents)\n",
        "      if  T==\"train_xlnet_words\" or T==\"train_xlnet_pred\" or T== \"dev_xlnet_words\" or T== \"dev_xlnet_pred\" or T==\"test_xlnet_words_RE\" or T==\"test_xlnet_pred_RE\" or T==\"test_xlnet_words_\" or T==\"test_xlnet_pred_\"  : #13 july 2020 added this or T==\"test_xlnet_words_\" or T==\"test_xlnet_pred_\" :\n",
        "          return encodeXLnetInputs(sents,T)\n",
        "      return (encode_inputs(sents))\n",
        "\n",
        "def get_sents_from_df( df):\n",
        "      #Split a data frame by rows accroding to the sentences\n",
        "      return [df[df.run_id == run_id]\n",
        "            for run_id\n",
        "            in sorted(set(df.run_id.values))]\n",
        "def transform_labels(labels):\n",
        "        \"\"\"\n",
        "        Encode a list of textual labels\n",
        "        \"\"\"\n",
        "        # Fallback:\n",
        "        classes  = list(classes_())\n",
        "        return [classes.index(label) for label in labels]\n",
        "\n",
        "\n",
        "def get_fixed_size(sents):\n",
        "        \"\"\"\n",
        "        Partition sents into lists of sent_maxlen elements\n",
        "        (execept the last in each sentence, which might be shorter)\n",
        "        \"\"\"\n",
        "        return [sent[s_ind : s_ind + sent_maxlen]\n",
        "                for sent in sents\n",
        "                for s_ind in range(0, len(sent), sent_maxlen)]\n",
        "\n",
        "\n",
        "def encode_outputs(sents):\n",
        "        output_encodings = []\n",
        "        sents = get_fixed_size(sents)\n",
        "        # Encode outputs\n",
        "        for sent in sents:\n",
        "            output_encodings.append(list(np_utils.to_categorical(list(transform_labels(sent.label.values)),\n",
        "                                                                 num_classes = num_of_classes())))\n",
        "\n",
        "        # Pad / truncate to maximum length\n",
        "\n",
        "        return np.ndarray(shape = (len(sents),\n",
        "                                  sent_maxlen,\n",
        "                                  num_of_classes()),\n",
        "                          buffer = np.array(pad_sequences(output_encodings,\n",
        "                                                          lambda : \\\n",
        "                                                            np.zeros(num_of_classes()),\n",
        "                                                          maxlen = sent_maxlen)))\n",
        "def get_head_pred_word( full_sent):\n",
        "\n",
        "        \"\"\"\n",
        "        Get the head predicate word from a full sentence conll.\n",
        "        \"\"\"\n",
        "        assert(len(set(full_sent.head_pred_id.values)) == 1) # Sanity check\n",
        "        pred_ind = full_sent.head_pred_id.values[0]\n",
        "\n",
        "        return full_sent.word.values[pred_ind] \\\n",
        "            if pred_ind != -1 \\\n",
        "               else full_sent.pred.values[0].split(\" \")[0]\n",
        "def predict_classes():\n",
        "        \"\"\"\n",
        "        Predict to the number of classes\n",
        "        Named arguments are passed to the keras function\n",
        "        \"\"\"\n",
        "        return lambda x: stack(x,\n",
        "                                    [lambda : TimeDistributed(Dense(output_dim = num_of_classes(),\n",
        "                                                                    activation = \"softmax\"))] +\n",
        "                                    [lambda : TimeDistributed(Dense(hidden_units,\n",
        "                                                                    activation='relu'))] * 3)\n",
        "\n",
        "def encode_inputs(sents):\n",
        "        word_inputs = []\n",
        "        pred_inputs = []\n",
        "        pos_inputs = []\n",
        "\n",
        "        assert(all([len(set(sent.run_id.values)) == 1\n",
        "                    for sent in sents]))\n",
        "\n",
        "        run_id_to_pred = dict([(int(sent.run_id.values[0]),\n",
        "                                get_head_pred_word(sent))\n",
        "                               for sent in sents])\n",
        "        # Construct a mapping from running word index to pos\n",
        "        word_id_to_pos = {}\n",
        "        for sent in sents:\n",
        "            indices = sent.index.values\n",
        "            words = sent.word.values\n",
        "\n",
        "            for index, word in zip(indices,\n",
        "                                    spacy_ws(\" \".join(words))):\n",
        "                word_id_to_pos[index] = word.tag_  #tag_ get the tag of the word by spacy\n",
        "\n",
        "\n",
        "        fixed_size_sents = get_fixed_size(sents)\n",
        "\n",
        "\n",
        "        for sent in fixed_size_sents:\n",
        "\n",
        "            assert(len(set(sent.run_id.values)) == 1)\n",
        "\n",
        "            word_indices = sent.index.values\n",
        "            sent_words = sent.word.values\n",
        "\n",
        "\n",
        "            pos_tags_encodings = [p for (x,p) in nltk.pos_tag(sent_words)]\n",
        "            word_encodings = [ w for w in sent_words]\n",
        "            pred_word = run_id_to_pred[int(sent.run_id.values[0])]\n",
        "\n",
        "            pred_word_encodings = [pred_word]\n",
        "\n",
        "            word_inputs.append([Sample(w) for w in word_encodings])\n",
        "            pred_inputs.append([Sample(w) for w in pred_word_encodings])\n",
        "            pos_inputs.append([Sample(pos) for pos in pos_tags_encodings])\n",
        "\n",
        "        ret = defaultdict(lambda: [])\n",
        "\n",
        "        for name, sequence in zip([\"word_inputs\", \"predicate_inputs\",\"postags_inputs\"],\n",
        "                                  [word_inputs, pred_inputs,pos_inputs]):\n",
        "            for samples in pad_sequences(sequence,\n",
        "                                         pad_func = lambda : Pad_sample(),\n",
        "                                         maxlen = sent_maxlen):\n",
        "                ret[name].append([sample.encode() for sample in samples])\n",
        "        injy={k: np.array(v) for k, v in ret.items()}\n",
        "        return {k: np.array(v) for k, v in ret.items()}\n",
        "\n",
        "def getPOS(sents):\n",
        "        word_inputs = []\n",
        "        pred_inputs = []\n",
        "        pos_inputs = []\n",
        "        assert(all([len(set(sent.run_id.values)) == 1\n",
        "                    for sent in sents]))\n",
        "\n",
        "        run_id_to_pred = dict([(int(sent.run_id.values[0]),\n",
        "                                get_head_pred_word(sent))\n",
        "                               for sent in sents])\n",
        "\n",
        "        # Construct a mapping from running word index to pos\n",
        "        word_id_to_pos = {}\n",
        "        for sent in sents:\n",
        "            indices = sent.index.values\n",
        "            words = sent.word.values\n",
        "\n",
        "            for index, word in zip(indices,\n",
        "                                    spacy_ws(\" \".join(words))):\n",
        "                word_id_to_pos[index] = word.tag_  #tag_ get the tag of the word by spacy\n",
        "\n",
        "        fixed_size_sents = get_fixed_size(sents)\n",
        "\n",
        "        allPosEncoding=[]\n",
        "\n",
        "        for sent in fixed_size_sents:\n",
        "\n",
        "            assert(len(set(sent.run_id.values)) == 1)\n",
        "\n",
        "            word_indices = sent.index.values\n",
        "            sent_words = sent.word.values\n",
        "\n",
        "            pos_tags_encodings = [p for (x,p) in nltk.pos_tag(sent_words)]\n",
        "            word_encodings = [ w for w in sent_words]\n",
        "\n",
        "            pred_word = run_id_to_pred[int(sent.run_id.values[0])]\n",
        "\n",
        "            pred_word_encodings = [pred_word]\n",
        "\n",
        "            word_inputs.append([Sample(w) for w in word_encodings])\n",
        "            pred_inputs.append([Sample(w) for w in pred_word_encodings])\n",
        "            pos_inputs.append([Sample(pos) for pos in pos_tags_encodings])\n",
        "            allPosEncoding.append(pos_tags_encodings)\n",
        "        return allPosEncoding\n",
        "\n",
        "def encodeXLnetInputs(sents,T):\n",
        "        word_inputs = []\n",
        "        pred_inputs = []\n",
        "        pos_inputs = []\n",
        "        assert(all([len(set(sent.run_id.values)) == 1\n",
        "                    for sent in sents]))\n",
        "\n",
        "        run_id_to_pred = dict([(int(sent.run_id.values[0]),\n",
        "                                get_head_pred_word(sent))\n",
        "                               for sent in sents])\n",
        "\n",
        "        # Construct a mapping from running word index to pos\n",
        "        word_id_to_pos = {}\n",
        "        for sent in sents:\n",
        "            indices = sent.index.values\n",
        "            words = sent.word.values\n",
        "\n",
        "\n",
        "            for index, word in zip(indices,\n",
        "                                    spacy_ws(\" \".join(words))):\n",
        "                word_id_to_pos[index] = word.tag_  #tag_ get the tag of the word by spacy\n",
        "\n",
        "\n",
        "        fixed_size_sents = get_fixed_size(sents)\n",
        "        allPosEncoding=[] #19 jan 2020\n",
        "        allWordsEncodingPartial=[]\n",
        "        allWordsEncoding=[]\n",
        "        allPredEncodingPartial=[]\n",
        "        allPredEncoding=[]\n",
        "        for sent in fixed_size_sents:\n",
        "\n",
        "            assert(len(set(sent.run_id.values)) == 1)\n",
        "\n",
        "            word_indices = sent.index.values\n",
        "            sent_words = sent.word.values\n",
        "\n",
        "            pos_tags_encodings = [p for (x,p) in nltk.pos_tag(sent_words)]\n",
        "            word_encodings = [ w for w in sent_words]\n",
        "\n",
        "            pred_word = run_id_to_pred[int(sent.run_id.values[0])]\n",
        "\n",
        "            pred_word_encodings = [pred_word]\n",
        "\n",
        "            word_inputs.append([Sample(w) for w in word_encodings])\n",
        "            pred_inputs.append([Sample(w) for w in pred_word_encodings])\n",
        "            pos_inputs.append([Sample(pos) for pos in pos_tags_encodings])\n",
        "            allPosEncoding.append(pos_tags_encodings)\n",
        "            allWordsEncodingPartial.append(word_encodings) #for Xlnet output is ['a','b'] need to make it space seperated using join\n",
        "            allPredEncodingPartial.append(pred_word_encodings)\n",
        "\n",
        "        if T==\"train_xlnet_words\" or T== \"dev_xlnet_words\" or T==\"test_xlnet_words_RE\" or T==\"test_xlnet_words_\" :\n",
        "          for sentence in allWordsEncodingPartial:\n",
        "            x=[' '.join(sentence)]\n",
        "            allWordsEncoding.append(x)\n",
        "          return allWordsEncoding\n",
        "        elif  T==\"train_xlnet_pred\" or T== \"dev_xlnet_pred\"  or T==\"test_xlnet_pred_RE\" or T==\"test_xlnet_pred_\":\n",
        "          for sentence in allPredEncodingPartial:\n",
        "            x=[' '.join(sentence)]\n",
        "            allPredEncoding.append(x)\n",
        "          return allPredEncoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading in the Training file and displaying for Validation purposes"
      ],
      "metadata": {
        "id": "4MLNeOrnFbkg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNqyxcgbrC3F",
        "outputId": "3683d84f-3603-4680-bf18-2a8a01a3bfba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 906 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.27.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.12)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en\n",
        "import spacy\n",
        "spacy.load('en')\n",
        "import pandas\n",
        "import numpy as np\n",
        "from keras.layers import Reshape, Flatten\n",
        "from keras.models import load_model\n",
        "from keras.layers.core import Dropout, Activation\n",
        "import spacy\n",
        "from symbols import SPACY_POS_TAGS\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "from spacy_wrapper import spacy_whitespace_parser as spacy_ws\n",
        "from keras.layers.merge import concatenate, Concatenate,multiply\n",
        "from keras.layers import TimeDistributed, Input, Bidirectional, Dense, Embedding, LSTM, Conv1D,Conv2D, Conv3D, GlobalMaxPooling1D, RepeatVector, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras.layers import Masking, Activation, Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIA4EmUGq262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "4cfc4066-f2d7-4275-f97f-15ee97b8c130"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-43e0e053c075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m dfE = pandas.read_csv(train_fn, sep= \"\\t\",\n\u001b[1;32m      4\u001b[0m                          \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                          keep_default_na=False)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Berkeley/W266/Project/Data/Malware/all_MLB_3.oie.conll'"
          ]
        }
      ],
      "source": [
        "train_fn=\"/content/gdrive/MyDrive/Berkeley/W266/Project/Data/Malware/all_MLB_3.oie.conll\"\n",
        "\n",
        "dfE = pandas.read_csv(train_fn, sep= \"\\t\",\n",
        "                         header=0,\n",
        "                         keep_default_na=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5upZt3_FEW7"
      },
      "outputs": [],
      "source": [
        "dfE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMAVyzT7crNj"
      },
      "source": [
        "#Block 4: Train File--> Adjust it according to your dataset and embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoAFE0aJ14IR"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en\n",
        "import spacy\n",
        "spacy.load('en')\n",
        "import pandas\n",
        "import numpy as np\n",
        "from keras.layers import Reshape, Flatten\n",
        "from keras.models import load_model\n",
        "from keras.layers.core import Dropout, Activation\n",
        "import spacy\n",
        "\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "from spacy_wrapper import spacy_whitespace_parser as spacy_ws\n",
        "from keras.layers.merge import concatenate, Concatenate,multiply\n",
        "from keras.layers import TimeDistributed, Input, Bidirectional, Dense, Embedding, LSTM, Conv1D,Conv2D, Conv3D, GlobalMaxPooling1D, RepeatVector, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras.layers import Masking, Activation, Input\n",
        "\n",
        "\n",
        "#-------Train File-------------\n",
        "train_fn=\"/content/gdrive/MyDrive/Berkeley/W266/Project/Data/Malware/all_MLB_3.oie.conll\"\n",
        "\n",
        "dfE = pandas.read_csv(train_fn, sep= \"\\t\",\n",
        "                         header=0,\n",
        "                         keep_default_na=False)\n",
        "\n",
        "sents = get_sents_from_df(dfE)\n",
        "\n",
        "train_textEI = dfE.groupby(dfE['word_id'].eq(0).cumsum())['word'].apply(lambda x: [' '.join(x)]).tolist()\n",
        "train_wordsTokens=[]\n",
        "\n",
        "for i in train_textEI:\n",
        "  for j in i:\n",
        "    train_wordsTokens.append(j.split())\n",
        "\n",
        "train_wordsTokens_trunc=[]\n",
        "for i in  train_wordsTokens:\n",
        "  train_wordsTokens_trunc.append(i[:sent_maxlen])\n",
        "\n",
        "train_predIE =  dfE.groupby(dfE['word_id'].eq(0).cumsum())['pred'].apply(lambda x: [' '.join(x)]).tolist()\n",
        "\n",
        "train_predTokens=[]\n",
        "for i in train_predIE:\n",
        "  for j in i:\n",
        "    train_predTokens.append(j.split())\n",
        "\n",
        "train_predTokens_trunc=[]\n",
        "for i in  train_predTokens:\n",
        "  train_predTokens_trunc.append(i[:sent_maxlen])\n",
        "\n",
        "Label_train=load_dataset(train_fn,\"train\")\n",
        "X_train_elmo=load_dataset_encodeinputs(train_fn,\"train\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6IPIjWfl1ZC"
      },
      "source": [
        "# Block 4.2: Calling functions to get XLNet inputs+ shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe2joP3_SIxt"
      },
      "source": [
        "**The snippet below is used for setting up the inputs for Embeddings**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eSoAzB0wrl0"
      },
      "outputs": [],
      "source": [
        "X_train_xlnet_Words=load_dataset_encodeinputs(train_fn,\"train_xlnet_words\")\n",
        "mydiffLenSet=set()\n",
        "for sentence in X_train_xlnet_Words:\n",
        "  mydiffLenSet.add(len(sentence[0].split()))\n",
        "X_train_xlnet_pred=load_dataset_encodeinputs(train_fn,\"train_xlnet_pred\")\n",
        "train_posIE =  load_dataset_encodeinputs(train_fn,\"POS_train\")\n",
        "train_posIE[0:5]\n",
        "newTrain_posIE=[]\n",
        "count=0\n",
        "for sentence in train_posIE:\n",
        "   count+=1\n",
        "   newTrain_posIE.append(' '.join(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnKKDYKknx0c"
      },
      "source": [
        "# **Block 5:** Dealing with padded sentences and then calling create_xlnet_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-2Fx3f3F_CP"
      },
      "outputs": [],
      "source": [
        "for x in X_train_elmo['predicate_inputs']:\n",
        "  x[x == '0'] =  x[0]\n",
        "train_PredicateXLNET= create_XLNET_embeddings(\"elmo\", X_train_xlnet_pred, sent_maxlen)\n",
        "for y in X_train_elmo['word_inputs']:\n",
        "    y[y == '0'] = y[0]\n",
        "train_WordsXLNET= create_XLNET_embeddings(\"elmo\", X_train_xlnet_Words, sent_maxlen)\n",
        "for z in X_train_elmo['postags_inputs']:\n",
        "    z[z == '0'] = z[0]\n",
        "train_POSXLNET= create_XLNET_embeddings(\"elmo\", train_posIE, sent_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxoJZG_3s-D7"
      },
      "source": [
        "# Block 6: Dev File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlnDt9beVENm"
      },
      "source": [
        "In case you have a validation set; can be added as a part of test set by splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gjyMeKxLiEL"
      },
      "outputs": [],
      "source": [
        "#-------Dev File-------------\n",
        "\n",
        "dev_fn=\"/content/gdrive/MyDrive/Berkeley/W266/Project/Data/Malware/all_MLB_2.oie_corrected_final.conll\"\n",
        "Label_dev=load_dataset(dev_fn,\"d\")\n",
        "X_dev_Xlnet_words=load_dataset_encodeinputs(dev_fn,\"dev_xlnet_words\")\n",
        "X_dev_Xlnet_pred=load_dataset_encodeinputs(dev_fn,\"dev_xlnet_pred\")\n",
        "X_dev_Xlnet_pos=load_dataset_encodeinputs(dev_fn,\"dev_xlnet_pos\")\n",
        "dev_PredicateXLNET= create_XLNET_embeddings(\"elmo\", X_dev_Xlnet_pred, sent_maxlen)\n",
        "dev_WordsXLNET= create_XLNET_embeddings(\"elmo\", X_dev_Xlnet_words, sent_maxlen)\n",
        "dev_POSXLNET= create_XLNET_embeddings(\"elmo\", X_dev_Xlnet_pos, sent_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZRbpK4u1ual"
      },
      "source": [
        "# Block 7: The Model (stacking layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaJo0IZ_G0Xh"
      },
      "outputs": [],
      "source": [
        "!pip install keras-attention\n",
        "!pip install keras-self-attention\n",
        "import tensorflow.python.keras.layers\n",
        "from tensorflow.keras.layers import Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhwOyskBHWKY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "from keras import layers\n",
        "import pandas\n",
        "import numpy as np\n",
        "from keras.layers import Reshape, Flatten\n",
        "from keras.models import load_model\n",
        "from keras.layers.core import Dropout, Activation\n",
        "from collections import defaultdict\n",
        "from keras.layers.merge import concatenate, Concatenate,multiply\n",
        "from keras.layers import TimeDistributed, Input, Bidirectional, Dense, Embedding, LSTM, Conv1D,Conv2D, Conv3D, GlobalMaxPooling1D, RepeatVector, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras.layers import Masking, Activation, Input\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, concatenate, Dropout, LSTM, GRU, Bidirectional, TimeDistributed, Masking\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3XPE_NQ1UdQ"
      },
      "outputs": [],
      "source": [
        "emb_size=1024\n",
        "def stack_latent_layers(n):\n",
        "        return lambda x: stack(x, [lambda : Bidirectional(GRU(hidden_units,\n",
        "                                                                    return_sequences = True))] * n )\n",
        "def stack(x, layers):\n",
        "        if not layers:\n",
        "            return x\n",
        "        else:\n",
        "            return layers[0]()(stack(x, layers[1:]))\n",
        "def predict_classes():\n",
        "        return lambda x: stack(x,\n",
        "                                    [lambda : TimeDistributed(Dense(units = num_of_classes(),\n",
        "                                                                    activation = \"softmax\"))] +\n",
        "                                    [lambda : TimeDistributed(Dense(hidden_units,\n",
        "                                                                    activation='relu'))] * 3)\n",
        "\n",
        "inputs = [Input((sent_maxlen,emb_size), dtype='float32', name='word_inputs'),\n",
        "            Input((sent_maxlen,emb_size), dtype='float32', name='predicate_inputs'),\n",
        "          Input((sent_maxlen,emb_size), dtype='float32', name='POS_inputs'),]\n",
        "\n",
        "embeddingsCon = [inputs[0],\n",
        "            inputs[1],\n",
        "                inputs[2]]\n",
        "\n",
        "con11 = keras.layers.concatenate(embeddingsCon)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HL4b6vMd9fP"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRevM99EcAM9"
      },
      "source": [
        "## Model 1 : Bi-LSTM without Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shDcsHP7cA_O"
      },
      "outputs": [],
      "source": [
        "# Constructing Model\n",
        "\n",
        "# Setting up tensorboard logs directory\n",
        "log_dir = \"logs/fit/model_LSTM/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "bilstm1=Bidirectional(LSTM(hidden_units, return_sequences = True))(con11)\n",
        "bilstm2=Bidirectional(LSTM(hidden_units, return_sequences = True))(bilstm1)\n",
        "\n",
        "dropout = Dropout(0.1)(bilstm2)\n",
        "td=TimeDistributed(Dense(hidden_units,activation='relu'))(dropout)\n",
        "outputs=TimeDistributed(Dense(units = num_of_classes(),activation = \"softmax\"))(td)\n",
        "model_LSTM=Model(inputs, outputs)\n",
        "model_LSTM.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['categorical_accuracy'])\n",
        "model_LSTM.summary()\n",
        "X=[train_WordsXLNET,train_PredicateXLNET,train_POSXLNET]\n",
        "X_dev=[dev_WordsXLNET,dev_POSXLNET,dev_POSXLNET]\n",
        "model_LSTM.fit(X, Label_train,\n",
        "                       batch_size = 5,\n",
        "                       epochs = 20,\n",
        "                       validation_data = (X_dev, Label_dev),\n",
        "                       callbacks=[tensorboard_callback]\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEvGGmWkDUbE"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit/model_LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vpXh0qMAZRc"
      },
      "source": [
        "# **Block 8**: Testing-->load dataset for test set +  embedding + model.predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS6tF1H9JNP4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# add your test file here\n",
        "\n",
        "test_fn=\"/content/gdrive/MyDrive/Berkeley/W266/Project/Data/Malware/all_MLB_1.oie.conll\"\n",
        "Y=load_datasetTestRE(test_fn,\"test\")\n",
        "X_test_Xlnet_words=load_dataset_encodeinputs(test_fn,\"test_xlnet_words_\")\n",
        "X_test_Xlnet_pred=load_dataset_encodeinputs(test_fn,\"test_xlnet_pred_\")\n",
        "X_test_Xlnet_pos=load_dataset_encodeinputs(test_fn,\"test_xlnet_pos_\")\n",
        "test_PredicateXLNET= create_XLNET_embeddings(\"elmo\", X_test_Xlnet_pred, sent_maxlen)\n",
        "test_WordsXLNET= create_XLNET_embeddings(\"elmo\", X_test_Xlnet_words, sent_maxlen)\n",
        "test_POSXLNET= create_XLNET_embeddings(\"elmo\", X_test_Xlnet_pos, sent_maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XTEST=[test_WordsXLNET,test_PredicateXLNET,test_POSXLNET]\n",
        "y_LSTM = model_LSTM.predict(XTEST)"
      ],
      "metadata": {
        "id": "hktGrZCUr0r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLOOONGEEBP9"
      },
      "source": [
        "# **Block 9 :** consolidate labels and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtxD8uWrdiWH"
      },
      "outputs": [],
      "source": [
        "# Create a labels dictionary structure\n",
        "labels_dic = dict([(label, dfE[dfE.label == label].shape[0]) for\n",
        "                       label in dfE.label.unique()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxCWJ3SkdsEi"
      },
      "outputs": [],
      "source": [
        "labels_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyBRcwM-rsxj"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import logging\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "\n",
        "myLabelsDict={k:v for k,v in enumerate(labels_dic)}\n",
        "for i,label in enumerate(y_LSTM[10]):\n",
        "  maxVal=np.max(label)\n",
        "  index=np.where(label==maxVal)\n",
        "\n",
        "def sample_labels( y, num_of_sents = 5, num_of_samples = 10,\n",
        "                      num_of_classes = 3, start_index = 5, get_prob = True):\n",
        "        classes = classes_()\n",
        "        ret = []\n",
        "        x=list(y)\n",
        "        for sent in x[:num_of_sents]:\n",
        "            cur = []\n",
        "            for word in sent[start_index: start_index + num_of_samples]:\n",
        "                sorted_prob = am(word)\n",
        "                cur.append([(classes[ind], word[ind]) if get_prob\n",
        "                            else classes[ind]\n",
        "                            for ind in sorted_prob[:num_of_classes]])\n",
        "            ret.append(cur)\n",
        "        return ret\n",
        "\n",
        "def consolidate_labels(labels):\n",
        "        x=map(consolidate_label , labels)\n",
        "        return list(x)\n",
        "\n",
        "def consolidate_label(label):\n",
        "        return label.split(\"-\")[0] if label.startswith(\"O\") else label\n",
        "\n",
        "def transform_output_probs(y, get_prob = False):\n",
        "        return np.array(sample_labels(y,\n",
        "                                  num_of_sents = len(list(y)), # all sentences\n",
        "                                  num_of_samples = max(list(map(len, y))), # all words\n",
        "                                  num_of_classes = 1, # Only top probability\n",
        "                                  start_index = 0, # all sentences\n",
        "                                  get_prob = get_prob, # Indicate whether to get only labels\n",
        "\n",
        "               ))\n",
        "# Get most probable predictions and flatten\n",
        "am = lambda myList: [i[0] for i in sorted(enumerate(myList), key=lambda x:x[1], reverse= True)]\n",
        "Y1 = consolidate_labels(transform_output_probs(Y).flatten())\n",
        "y2 = consolidate_labels(transform_output_probs(y_LSTM).flatten())\n",
        "\n",
        "logging.basicConfig(level = logging.DEBUG)\n",
        "\n",
        "ret = []\n",
        "\n",
        "eval_metrics = [\n",
        "                (\"F1 (micro)\", lambda Y1, y2: metrics.f1_score(Y1, y2,average = 'micro')),\n",
        "                (\"Precision (micro)\",lambda Y1, y2: metrics.precision_score(Y1, y2,average = 'micro')),\n",
        "                (\"Recall (micro)\",lambda Y1, y2: metrics.recall_score(Y1, y2,average = 'micro')),\n",
        "                (\"Accuracy\", metrics.accuracy_score),\n",
        "               ]\n",
        "\n",
        "eval_metrics2 = [\n",
        "                (\"F1 (wieghted)\", lambda Y1, y2: metrics.f1_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Precision (wieghted)\",lambda Y1, y2: metrics.precision_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Recall (wieghted)\",lambda Y1, y2: metrics.recall_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Accuracy\", metrics.accuracy_score),\n",
        "               ]\n",
        "for (metric_name, metric_func) in eval_metrics:\n",
        "        ret.append((metric_name, metric_func(Y1, y2)))\n",
        "        logging.debug(\"calculating {}\".format(ret[-1]))\n",
        "\n",
        "for (metric_name, metric_func) in eval_metrics2:\n",
        "        ret.append((metric_name, metric_func(Y1, y2)))\n",
        "        logging.debug(\"calculating {}\".format(ret[-1]))\n",
        "\n",
        "for (metric_name, metric_val) in ret:\n",
        "     logging.info(\"{}: {:.4f}\".format(metric_name,\n",
        "                                             metric_val))\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return fig\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "xx = list(labels_dic.keys())\n",
        "conM=confusion_matrix(Y1,y2)\n",
        "figg=print_confusion_matrix(conM, xx, figsize = (10,7), fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBjAubRfY4eG"
      },
      "source": [
        "## Model 2 BI-LSTM with Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltJWJqC4Y-v2"
      },
      "outputs": [],
      "source": [
        "# Constructing Model 2\n",
        "\n",
        "# Setting up tensorboard logs directory\n",
        "log_dir = \"logs/fit/model_LSTM_ATTN/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "bilstm1=Bidirectional(LSTM(hidden_units, return_sequences = True))(con11)\n",
        "bilstm2=Bidirectional(LSTM(hidden_units, return_sequences = True))(bilstm1)\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([bilstm1, bilstm2])\n",
        "\n",
        " # Concat attention and bigru2 outputs\n",
        "concat_outputs = Concatenate(axis=-1, name='concat_layer')([bilstm2, attn_out])\n",
        "dropout = Dropout(0.1)(concat_outputs)\n",
        "\n",
        "td=TimeDistributed(Dense(hidden_units,activation='relu'))(dropout)\n",
        "outputs=TimeDistributed(Dense(units = num_of_classes(),activation = \"softmax\"))(td)\n",
        "model_LSTM_ATTN=Model(inputs, outputs)\n",
        "model_LSTM_ATTN.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['categorical_accuracy'])\n",
        "model_LSTM_ATTN.summary()\n",
        "X=[train_WordsXLNET,train_PredicateXLNET,train_POSXLNET]\n",
        "X_dev=[dev_WordsXLNET,dev_POSXLNET,dev_POSXLNET]\n",
        "model_LSTM_ATTN.fit(X, Label_train,\n",
        "                       batch_size = 5,\n",
        "                       epochs = 20,\n",
        "                       validation_data = (X_dev, Label_dev),\n",
        "                       callbacks=[tensorboard_callback]\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvvLCwulIs1_"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit/model_LSTM_ATTN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prCqYH0iZyEb"
      },
      "source": [
        "## Evaluating on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGTxhPCMZzy6"
      },
      "outputs": [],
      "source": [
        "XTEST=[test_WordsXLNET,test_PredicateXLNET,test_POSXLNET]\n",
        "y_LSTM_ATTN = model_LSTM_ATTN.predict(XTEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ansg2L50Z6bo"
      },
      "outputs": [],
      "source": [
        "for i,label in enumerate(y_LSTM_ATTN[10]):\n",
        "  maxVal=np.max(label)\n",
        "  index=np.where(label==maxVal)\n",
        "\n",
        "# Get most probable predictions and flatten\n",
        "am = lambda myList: [i[0] for i in sorted(enumerate(myList), key=lambda x:x[1], reverse= True)]\n",
        "Y1 = consolidate_labels(transform_output_probs(Y).flatten())\n",
        "y2 = consolidate_labels(transform_output_probs(y_LSTM_ATTN).flatten())\n",
        "\n",
        "logging.basicConfig(level = logging.DEBUG)\n",
        "\n",
        "ret = []\n",
        "\n",
        "eval_metrics = [\n",
        "                (\"F1 (micro)\", lambda Y1, y2: metrics.f1_score(Y1, y2, average = 'micro')),\n",
        "                (\"Precision (micro)\",lambda Y1, y2: metrics.precision_score(Y1, y2, average = 'micro')),\n",
        "                (\"Recall (micro)\",lambda Y1, y2: metrics.recall_score(Y1, y2, average = 'micro')),\n",
        "                (\"Accuracy\", metrics.accuracy_score),\n",
        "               ]\n",
        "\n",
        "eval_metrics2 = [\n",
        "                (\"F1 (wieghted)\", lambda Y1, y2: metrics.f1_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Precision (wieghted)\",lambda Y1, y2: metrics.precision_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Recall (wieghted)\",lambda Y1, y2: metrics.recall_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Accuracy\", metrics.accuracy_score),\n",
        "               ]\n",
        "for (metric_name, metric_func) in eval_metrics:\n",
        "        ret.append((metric_name, metric_func(Y1, y2)))\n",
        "        logging.debug(\"calculating {}\".format(ret[-1]))\n",
        "\n",
        "for (metric_name, metric_func) in eval_metrics2:\n",
        "        ret.append((metric_name, metric_func(Y1, y2)))\n",
        "        logging.debug(\"calculating {}\".format(ret[-1]))\n",
        "\n",
        "for (metric_name, metric_val) in ret:\n",
        "     logging.info(\"{}: {:.4f}\".format(metric_name,\n",
        "                                             metric_val))\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return fig\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "xx = list(labels_dic.keys())\n",
        "conM=confusion_matrix(Y1,y2)\n",
        "figg=print_confusion_matrix(conM, xx, figsize = (10,7), fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isPiDI2TyMIj"
      },
      "source": [
        "## Model 3 BI-GRU Without Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY2-DvijIRkG"
      },
      "outputs": [],
      "source": [
        "# Constructing Model 3\n",
        "\n",
        "# Setting up tensorboard logs directory\n",
        "log_dir = \"logs/fit/model_GRU/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "bigru1=Bidirectional(GRU(hidden_units, return_sequences = True))(con11)\n",
        "bigru2=Bidirectional(GRU(hidden_units, return_sequences = True))(bigru1)\n",
        "\n",
        "dropout = Dropout(0.1)(bigru2)\n",
        "td=TimeDistributed(Dense(hidden_units,activation='relu'))(dropout)\n",
        "outputs=TimeDistributed(Dense(units = num_of_classes(),activation = \"softmax\"))(td)\n",
        "model_GRU=Model(inputs, outputs)\n",
        "model_GRU.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['categorical_accuracy'])\n",
        "model_GRU.summary()\n",
        "X=[train_WordsXLNET,train_PredicateXLNET,train_POSXLNET]\n",
        "X_dev=[dev_WordsXLNET,dev_POSXLNET,dev_POSXLNET]\n",
        "model_GRU.fit(X, Label_train,\n",
        "                       batch_size = 5,\n",
        "                       epochs = 20,\n",
        "                       validation_data = (X_dev, Label_dev),\n",
        "                       callbacks=[tensorboard_callback]\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG5TS5HYJDYS"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit/model_GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlsszuFpDlG_"
      },
      "source": [
        "## Evaluating on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYtMA-8dDsJD"
      },
      "outputs": [],
      "source": [
        "XTEST=[test_WordsXLNET,test_PredicateXLNET,test_POSXLNET]\n",
        "y_GRU = model_GRU.predict(XTEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD0-QQjKGgcn"
      },
      "outputs": [],
      "source": [
        "for i,label in enumerate(y_GRU[10]):\n",
        "  maxVal=np.max(label)\n",
        "  index=np.where(label==maxVal)\n",
        "\n",
        "# Get most probable predictions and flatten\n",
        "am = lambda myList: [i[0] for i in sorted(enumerate(myList), key=lambda x:x[1], reverse= True)]\n",
        "Y1 = consolidate_labels(transform_output_probs(Y).flatten())\n",
        "y2 = consolidate_labels(transform_output_probs(y_GRU).flatten())\n",
        "\n",
        "logging.basicConfig(level = logging.DEBUG)\n",
        "\n",
        "ret = []\n",
        "\n",
        "eval_metrics = [\n",
        "                (\"F1 (micro)\", lambda Y1, y2: metrics.f1_score(Y1, y2, average = 'micro')),\n",
        "                (\"Precision (micro)\",lambda Y1, y2: metrics.precision_score(Y1, y2, average = 'micro')),\n",
        "                (\"Recall (micro)\",lambda Y1, y2: metrics.recall_score(Y1, y2, average = 'micro')),\n",
        "                (\"Accuracy\", metrics.accuracy_score),\n",
        "               ]\n",
        "\n",
        "eval_metrics2 = [\n",
        "                (\"F1 (wieghted)\", lambda Y1, y2: metrics.f1_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Precision (wieghted)\",lambda Y1, y2: metrics.precision_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Recall (wieghted)\",lambda Y1, y2: metrics.recall_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Accuracy\", metrics.accuracy_score),\n",
        "               ]\n",
        "for (metric_name, metric_func) in eval_metrics:\n",
        "        ret.append((metric_name, metric_func(Y1, y2)))\n",
        "        logging.debug(\"calculating {}\".format(ret[-1]))\n",
        "\n",
        "for (metric_name, metric_func) in eval_metrics2:\n",
        "        ret.append((metric_name, metric_func(Y1, y2)))\n",
        "        logging.debug(\"calculating {}\".format(ret[-1]))\n",
        "\n",
        "for (metric_name, metric_val) in ret:\n",
        "     logging.info(\"{}: {:.4f}\".format(metric_name,\n",
        "                                             metric_val))\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return fig\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "xx = list(labels_dic.keys())\n",
        "conM=confusion_matrix(Y1,y2)\n",
        "figg=print_confusion_matrix(conM, xx, figsize = (10,7), fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziLXBHNsMNH7"
      },
      "source": [
        "## Model 4 BI-GRU With Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX37lH47MVEM"
      },
      "outputs": [],
      "source": [
        "# Constructing Model 4\n",
        "\n",
        "# Setting up tensorboard logs directory\n",
        "log_dir = \"logs/fit/model_GRU_ATTN/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "bigru1=Bidirectional(GRU(hidden_units, return_sequences = True))(con11)\n",
        "bigru2=Bidirectional(GRU(hidden_units, return_sequences = True))(bigru1)\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([bigru1, bigru2])\n",
        "\n",
        " # Concat attention and bigru2 outputs\n",
        "concat_outputs = Concatenate(axis=-1, name='concat_layer')([bigru2, attn_out])\n",
        "\n",
        "dropout = Dropout(0.1)(concat_outputs)\n",
        "td=TimeDistributed(Dense(hidden_units,activation='relu'))(dropout)\n",
        "outputs=TimeDistributed(Dense(units = num_of_classes(),activation = \"softmax\"))(td)\n",
        "model_GRU_ATTN=Model(inputs, outputs)\n",
        "model_GRU_ATTN.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['categorical_accuracy'])\n",
        "model_GRU_ATTN.summary()\n",
        "X=[train_WordsXLNET,train_PredicateXLNET,train_POSXLNET]\n",
        "X_dev=[dev_WordsXLNET,dev_POSXLNET,dev_POSXLNET]\n",
        "model_GRU_ATTN.fit(X, Label_train,\n",
        "                       batch_size = 5,\n",
        "                       epochs = 20,\n",
        "                       validation_data = (X_dev, Label_dev),\n",
        "                       callbacks=[tensorboard_callback]\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05EI3CTZJQH6"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit/model_GRU_ATTN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGBNumdCYmsY"
      },
      "source": [
        "## Evaluating on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxyHKeSEQkyK"
      },
      "outputs": [],
      "source": [
        "XTEST=[test_WordsXLNET,test_PredicateXLNET,test_POSXLNET]\n",
        "y_GRU_ATTN = model_GRU_ATTN.predict(XTEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v3pWHokRGBK"
      },
      "outputs": [],
      "source": [
        "for i,label in enumerate(y_GRU_ATTN[10]):\n",
        "  maxVal=np.max(label)\n",
        "  index=np.where(label==maxVal)\n",
        "\n",
        "# Get most probable predictions and flatten\n",
        "am = lambda myList: [i[0] for i in sorted(enumerate(myList), key=lambda x:x[1], reverse= True)]\n",
        "Y1 = consolidate_labels(transform_output_probs(Y).flatten())\n",
        "y2 = consolidate_labels(transform_output_probs(y_GRU_ATTN).flatten())\n",
        "\n",
        "logging.basicConfig(level = logging.DEBUG)\n",
        "\n",
        "ret = []\n",
        "\n",
        "eval_metrics = [\n",
        "                (\"F1 (micro)\", lambda Y1, y2: metrics.f1_score(Y1, y2, average = 'micro')),\n",
        "                (\"Precision (micro)\",lambda Y1, y2: metrics.precision_score(Y1, y2, average = 'micro')),\n",
        "                (\"Recall (micro)\",lambda Y1, y2: metrics.recall_score(Y1, y2, average = 'micro')),\n",
        "                (\"Accuracy\", metrics.accuracy_score),\n",
        "               ]\n",
        "\n",
        "eval_metrics2 = [\n",
        "                (\"F1 (wieghted)\", lambda Y1, y2: metrics.f1_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Precision (wieghted)\",lambda Y1, y2: metrics.precision_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Recall (wieghted)\",lambda Y1, y2: metrics.recall_score(Y1, y2,average = 'weighted')),\n",
        "                (\"Accuracy\", metrics.accuracy_score),\n",
        "               ]\n",
        "for (metric_name, metric_func) in eval_metrics:\n",
        "        ret.append((metric_name, metric_func(Y1, y2)))\n",
        "        logging.debug(\"calculating {}\".format(ret[-1]))\n",
        "\n",
        "for (metric_name, metric_func) in eval_metrics2:\n",
        "        ret.append((metric_name, metric_func(Y1, y2)))\n",
        "        logging.debug(\"calculating {}\".format(ret[-1]))\n",
        "\n",
        "for (metric_name, metric_val) in ret:\n",
        "     logging.info(\"{}: {:.4f}\".format(metric_name,\n",
        "                                             metric_val))\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return fig\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "xx = list(labels_dic.keys())\n",
        "conM=confusion_matrix(Y1,y2)\n",
        "figg=print_confusion_matrix(conM, xx, figsize = (10,7), fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "nBqRHS7_Fz3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### As can be seen in the results from the experiments above the Bi-GRU with attention layer achieved the highest precision of 64% when comapred to a Bi-GRU without attention layer which achieved a precision of 61%."
      ],
      "metadata": {
        "id": "jESB5XrGGb5x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SgtvKwCPGdww"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4eb63fa479f4d96839e727c0ddf4ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ebdbe950b6041da9a881c6a3d4e1ce7",
              "IPY_MODEL_552add47ffc544b295c11bf206a24963",
              "IPY_MODEL_0d20b4c6f0c8437286eda40cd4bf59db"
            ],
            "layout": "IPY_MODEL_6db55541bde442b0af866cbac6b5eb8a"
          }
        },
        "6ebdbe950b6041da9a881c6a3d4e1ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07fbb3fb0cd14e038ba30b36c4ea1aed",
            "placeholder": "​",
            "style": "IPY_MODEL_d7762137ab8248edb18505a6a35351f7",
            "value": "Downloading: 100%"
          }
        },
        "552add47ffc544b295c11bf206a24963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b2906b95e04a41a5c29819985d178d",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49a5901e71554a9e91b76ac175644fb4",
            "value": 616
          }
        },
        "0d20b4c6f0c8437286eda40cd4bf59db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7955b12acec412699544b19bf5d8263",
            "placeholder": "​",
            "style": "IPY_MODEL_d005300539a74680a12efc4df9ec9f8a",
            "value": " 616/616 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "6db55541bde442b0af866cbac6b5eb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07fbb3fb0cd14e038ba30b36c4ea1aed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7762137ab8248edb18505a6a35351f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b2906b95e04a41a5c29819985d178d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a5901e71554a9e91b76ac175644fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7955b12acec412699544b19bf5d8263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d005300539a74680a12efc4df9ec9f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "515831f556884e828a6e992b2d45ca7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76c1106aa0cb4bf9bbc724a9f6244e7e",
              "IPY_MODEL_fbc87a275067477bbf21aa0b4b13f3b1",
              "IPY_MODEL_9e4ac76061b04a04b55509a06d65e756"
            ],
            "layout": "IPY_MODEL_83145666a7904f3fbc84a1d80acd83b3"
          }
        },
        "76c1106aa0cb4bf9bbc724a9f6244e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87998ac5d26045f1918b9044de0163ae",
            "placeholder": "​",
            "style": "IPY_MODEL_eb484ad1f9fb462eba401158cd819bfe",
            "value": "Downloading: 100%"
          }
        },
        "fbc87a275067477bbf21aa0b4b13f3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c6c9609906489fa8f0f038c6dae18d",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b29932257842417bbba283a66651de85",
            "value": 5069051
          }
        },
        "9e4ac76061b04a04b55509a06d65e756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dcdea470e7042b79e84efb4d81febfa",
            "placeholder": "​",
            "style": "IPY_MODEL_33e210e461b94cd6be87ce1ec0739f3f",
            "value": " 4.83M/4.83M [00:01&lt;00:00, 4.39MB/s]"
          }
        },
        "83145666a7904f3fbc84a1d80acd83b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87998ac5d26045f1918b9044de0163ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb484ad1f9fb462eba401158cd819bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06c6c9609906489fa8f0f038c6dae18d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29932257842417bbba283a66651de85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dcdea470e7042b79e84efb4d81febfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33e210e461b94cd6be87ce1ec0739f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84b2b958465946708d491b55de3bde20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c6bd31809c84286adfe94cb024d29e5",
              "IPY_MODEL_f39d609c8961479683b54cc2c40a1408",
              "IPY_MODEL_8c68b9f836a24e5b9721e7acb342dbcc"
            ],
            "layout": "IPY_MODEL_b40089e3908a41c4af3965f5789874f2"
          }
        },
        "7c6bd31809c84286adfe94cb024d29e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37413b4ee52b4e92a13b4518e9f11b80",
            "placeholder": "​",
            "style": "IPY_MODEL_4da5b5b6cacb4f54b4216d786b1b0a90",
            "value": "Downloading: 100%"
          }
        },
        "f39d609c8961479683b54cc2c40a1408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0132d6d671149928383f80e5208a39b",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14b0aa8eb4984b94b6a73e5791c23bb9",
            "value": 9096718
          }
        },
        "8c68b9f836a24e5b9721e7acb342dbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f1617f020e4c94b530f8da3522d522",
            "placeholder": "​",
            "style": "IPY_MODEL_12dae2270b114e2c8b7a6d9dc48bb5b7",
            "value": " 8.68M/8.68M [00:01&lt;00:00, 8.79MB/s]"
          }
        },
        "b40089e3908a41c4af3965f5789874f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37413b4ee52b4e92a13b4518e9f11b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da5b5b6cacb4f54b4216d786b1b0a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0132d6d671149928383f80e5208a39b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14b0aa8eb4984b94b6a73e5791c23bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07f1617f020e4c94b530f8da3522d522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12dae2270b114e2c8b7a6d9dc48bb5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e5d1f065ed04fb5aa9888b5cfb0ee5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83b107b3eeb14863b5551cf9250e78b3",
              "IPY_MODEL_63f6eaede3bb4ed5b0bdd2bafd835362",
              "IPY_MODEL_fd34db7a59454e6a9b50e8728e285789"
            ],
            "layout": "IPY_MODEL_d1b2883d5bf541848baaa07d51998995"
          }
        },
        "83b107b3eeb14863b5551cf9250e78b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c97aa01f5fce48d89539d5cd0a2a8b3f",
            "placeholder": "​",
            "style": "IPY_MODEL_71a679d2562f4182ae99870e4226b339",
            "value": "Downloading: 100%"
          }
        },
        "63f6eaede3bb4ed5b0bdd2bafd835362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c8a247162c429abbf086902753857b",
            "max": 2244861551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21abc1c9bcbc4f39b9b33d49e96169e7",
            "value": 2244861551
          }
        },
        "fd34db7a59454e6a9b50e8728e285789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7358b218b0ea473895465f321dd001c2",
            "placeholder": "​",
            "style": "IPY_MODEL_c4114a05f4bf414ba7093018cb0452d4",
            "value": " 2.09G/2.09G [03:43&lt;00:00, 5.08MB/s]"
          }
        },
        "d1b2883d5bf541848baaa07d51998995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97aa01f5fce48d89539d5cd0a2a8b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a679d2562f4182ae99870e4226b339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c8a247162c429abbf086902753857b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21abc1c9bcbc4f39b9b33d49e96169e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7358b218b0ea473895465f321dd001c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4114a05f4bf414ba7093018cb0452d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}